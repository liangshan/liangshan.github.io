<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Best Practice | Liangshan]]></title>
  <link href="https://liangshan.blog/blog/categories/best-practice/atom.xml" rel="self"/>
  <link href="https://liangshan.blog/"/>
  <updated>2018-05-09T14:44:18+08:00</updated>
  <id>https://liangshan.blog/</id>
  <author>
    <name><![CDATA[Liangshan]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[分布式系统架构概述（译）]]></title>
    <link href="https://liangshan.blog/blog/2018/05/04/distributed-architecture-concepts/"/>
    <updated>2018-05-04T11:58:05+08:00</updated>
    <id>https://liangshan.blog/blog/2018/05/04/distributed-architecture-concepts</id>
    <content type="html"><![CDATA[<p>我其实很少翻译东西，首先是因为英文和中文水平都有限，很难做到信达雅，其次一般的文章自己看过就结束了，很少有要翻译的冲动。这次要翻译的是一篇概括性很强的文章，讲的是分布式系统中需要了解的基础概念，值得保存下来经常回顾。</p>

<p>有趣的是，这篇文章在 <a href="https://news.ycombinator.com/item?id=16852295">hacker news</a> 和 <a href="https://www.reddit.com/r/programming/comments/8cxz7q/distributed_architecture_concepts_i_learned_while/">reddit</a> 上得到了基本相反的评价。我个人还是很认可这种概括性的文章的。就好像大学的课程大纲，有很强的指导作用。</p>

<p>以下是正文的译文，原文请戳<a href="http://blog.pragmaticengineer.com/distributed-architecture-concepts-i-have-learned-while-building-payments-systems/">这里</a>。</p>

<hr />

<p>两年前我做为移动开发工程师加入了 Uber，之前有一些后端开发的经验。我参与实现了 app 的支付模块——这个模块目前正在重写。之后，我开始进入工程管理领域，领导一个团队。这个团队负责很多和支付相关的后端系统，这意味着我更多的接触了后端开发的东西。</p>

<p>在 Uber 工作之前，我几乎没有分布式系统经验。我的教育背景是传统的计算机科学学位，之后做了十年全栈开发。虽然我之前略知一二，但我对分布式概念（如一致性，可用性或幂等性）没有太多的理解或欣赏。</p>

<p>在这篇文章中，我总结了一些构建大规模、高可用的分布式系统时需要了解的基本概念。这个系统就是 Uber 的支付系统，一个负载高达每秒数千次请求的系统，即使部分系统出现故障，关键支付功能也需要正常工作。 这是一个完整的清单吗？ 也许不是。 但如果我早点知道这些的话，会让我的生活变得更轻松。 因此，让我们深入了解 SLA、一致性、数据持久性、消息持久性、幂等性以及我在工作中需要学习的其他一些内容。</p>

<!--more-->


<h2>SLA</h2>

<p>对于那些每天处理数百万次事务的大型系统来说，出错几乎是无法避免的。我发现在深入计划一个系统之前，最重要的事情是先定义这个系统如何算「健康」。尽量用一些可衡量的指标来表示「健康」。通用方法是用 <a href="https://en.wikipedia.org/wiki/Service-level_agreement">SLA</a> 来衡量，即 service level agreements。我见过的最通用的 SLA 是：</p>

<ul>
<li><strong>可用性（Availability）</strong>：服务正常运行时间的百分比。显而易见的是应该努力让系统的可用性达到 100%，但做到这个目标不仅很难而且很贵。甚至像 VISA、Gmail、互联网供应商这样的大型且重要的系统都无法做到 100% 的可用性。历年来，他们总是会有那么几秒钟、几分钟、或者几小时不可用。对于大多数系统来说，4 个 9 的可用性（即 99.99%，换言之<a href="https://uptime.is/">每年不超过 50 分钟</a>不可用时间）即可被称为高可用。仅仅是达到这一水平通常已经意味着大量的工作要做了。</li>
<li><strong>准确性（Accuracy）</strong>：系统允许一些数据的丢失或不准确吗？如果允许，可以接受多大比例呢？对于我负责的支付系统来说，准确性的要求是 100%，意味着任何数据都不允许丢失。</li>
<li><strong>容量（Capacity）</strong>：系统预期可以承受多大的负载？这个指标通常使用 QPS(requests per second) 来表达。</li>
<li><strong>延迟（Latency）</strong>：系统应该在多久之后返回结果？95% 以及 <a href="https://www.quora.com/What-is-p99-latency">99%</a> 用户请求的响应时间是多少？系统通常会有一些噪音数据，所以取 95% 和 99% 请求的延迟时间是现实世界中的可行做法。</li>
</ul>


<p><strong>为什么 SLA 对于构建一个大型支付系统如此重要呢？</strong> 我们在构建将要替换当前系统的新系统。为了确保我们所做是正确的，即我们认为新系统是「更好」的，所以我们使用 SLA 来定义指标。其中可用性是我们优先级最高的要求。一旦确定了标准，我们就可以在架构过程中权衡选择来达到它。</p>

<h2>水平扩展（Horizontal scaling） Vs 垂直扩展（Vertical scaling）</h2>

<p>假如一个由新系统支撑的业务持续在增长，那么系统负载也在增加。到了某个节点，现有的设施已经无法支撑更多负载和容量。两种通常会考虑的扩展策略就是水平扩展和垂直扩展。</p>

<p>水平扩展就是通过加机器（或节点）来提升容量。水平扩展是目前分布式系统最流行的扩展方式，尤其是现如今对于集群来说，增加一台机器（或虚拟机）仅仅只是点一个按钮那么简单。</p>

<p>垂直扩展基本上就是「买一台更大更好的机器」，也就是更多核、更多进程、更多内存。对于分布式系统来说，垂直扩展通常没那么常见，因为垂直扩展往往要花费更多钱。但也有些大型网站，比如 Stack Overflow 就有过<a href="https://www.slideshare.net/InfoQ/scaling-stack-overflow-keeping-it-vertical-by-obsessing-over-performance">成功垂直扩展</a>来满足需求的案例。</p>

<p><strong>为什么扩展的策略对于构建一个大型支付系统如此重要呢？</strong> 我们早期就确定了支付系统应该是水平扩展的。虽然垂直扩展在某些场景下可行，但就目前市面上昂贵的单台大型主机负载能力而言，我们对它是否能承受目前支付系统的流量持悲观态度，更不用说将来。另外，我们团队有些工程师有大型支付系统工作的经验，当初他们想要使用能买到的最贵的主机来垂直扩展，然而失败了。（译者注：后面这些话好像并没有回答前面的问题）</p>

<h2>一致性（Consistency）</h2>

<p>可用性对于任何系统都是重要的。分布式系统往往构建于一批可用性相对较差的主机上。假设我们的目标是构建 99.999% 的可用性（即每年 5 分钟不可用），而我们使用的机器，平均只有 99.9% 的可用性（每年 8 小时不可用）。那么达到目标可用性的一种直接的方式就是使用一组这样的主机来组成集群。即便是某些节点不可用，其他的会保持可用来达到更高的可用性。</p>

<p>一致性是高可用系统的关键指标。如果系统的所有节点在同一时间返回相同的数据，则认为这个系统是一致的。回到刚才的话题，由于我们使用了一组机器来组成高可用集群，确保系统保持一致就至关重要了。为了确保每个节点都返回相同的信息，它们之间需要消息通信。但是，消息传递可能会失败、会丢失，有些节点甚至不可用。</p>

<p>一致性是一个我花了最多时间去理解和欣赏的概念。有很多一致性的模型，分布式系统中最流行的<a href="https://en.wikipedia.org/wiki/Consistency_model">几种模型</a>是<a href="https://en.wikipedia.org/wiki/Consistency_model">强一致性（strong consistency）</a>，<a href="https://www.cl.cam.ac.uk/teaching/0910/ConcDistS/11a-cons-tx.pdf">弱一致性（weak consistency）</a>和<a href="http://sergeiturukin.com/2017/06/29/eventual-consistency.html">最终一致性（eventual consistency）</a>。Hackernoon 的这篇<a href="https://hackernoon.com/eventual-vs-strong-consistency-in-distributed-databases-282fdad37cf7">强一致 vs 最终一致</a>给出了很好的可行的权衡建议。通常来讲，一致性越弱，系统越快，但拿不到最新数据的可能性也会越高。</p>

<p><strong>为什么一致性对于构建一个大型支付系统如此重要呢？</strong> 系统中的数据要保持一致。但要多一致呢？对于系统的某些组件来说，只有强一致能满足要求。比如，确认一个支付是否已经初始化的数据需要确保强一致性。其他一些组件，也就是那些不太重要的组件，最终一致性是可以考虑的选择。一个很好的例子是近期交易列表，就可以使用最终一致性策略来实现（这意味着最新的交易未必立刻出现在列表里，但换来了更低的延迟和更小的资源消耗）。</p>

<h2>数据耐久性（Data Durability）</h2>

<p><a href="https://en.wikipedia.org/wiki/Durability_(database_systems)">耐久性</a>意味着数据一旦被成功存储就可以一直继续使用。即使系统中的节点下线，崩溃或数据损坏也是如此。</p>

<p>不同的分布式数据库拥有不同级别的耐久性。有些系统支持机器/节点级别的耐久性，有些做到了集群级别而有些系统的耐久性并没有开箱即用。某种形式的数据复制是较为通用的提高耐久性的做法，因为把同一份数据存储在不同的节点上，即使有节点下线，数据仍然可以被访问。<a href="https://drivescale.com/2017/03/whatever-happened-durability/">这篇文章</a>很好的解释了为什么分布式系统做到耐久性是很大的挑战。</p>

<p><img width="800px" src="/images/custom/data-durability.png" /></p>

<p><strong>为什么数据耐久性对于构建一个支付系统如此重要呢？</strong> 这个系统的大部分组件而言，如此重要的数据是不允许丢失的。分布式的数据存储需要支持集群级别的数据耐久性，即使实例会崩溃，完成了的交易仍然还在。现如今大部分分布式数据存储服务，诸如 Cassandra、MongoDB、HDFS 或是 Dynamodb 全都支持不同级别的耐久性，并且通过配置都可以支持集群级别的耐久性。</p>

<h2>消息的持久化（Persistence）和耐久性（Durability）</h2>

<p>分布式系统中的节点进行计算、存储和相互发送消息。发送消息的一个关键性指标是消息送达的可靠性。对于重要的系统而言，常常不允许任何消息的丢失。</p>

<p>对于分布式系统而言，消息通讯通常由分布式消息服务完成，比如 RabbitMQ、Kafka。这些消息服务能支持（或配置后支持）不同级别的消息送达可靠性。</p>

<p>消息持久化的意思是当消息服务的节点发生了错误，已经发送的消息仍然会在错误解决之后被处理。消息耐久性则通常用在消息队列这一层。如果一个消息队列声明了耐久性，那么即使队列在消息发送之后掉线，仍然会在重新上线之后收到这条消息。<a href="https://developers.redhat.com/blog/2016/08/10/persistence-vs-durability-in-messaging/">这里</a>有一篇很好的文章是关于这个话题。</p>

<p><img width="800px" src="/images/custom/msg-durability.png" /></p>

<p><strong>为什么消息的持久化和耐久性对于构建一个支付系统如此重要呢？</strong> 我们有太多重要的消息经不起丢失，比如乘客刚刚初始化了行程的消息。也就是说我们的消息系统是不允许丢消息的，每条消息都会被投递一次。但是，每条消息精确投递一次和至少投递一次是截然不同的复杂度。我们最终决定了实现一个耐久的消息系统，每条消息至少被投递一次，在底层选择了一个消息总线（最终我们选择了 Kafka）。</p>

<h2>幂等性（Idempotency）</h2>

<p>分布式系统偶尔会出错，比如连接会断开或是请求会超时。客户端经常需要重试这些请求。一个幂等的系统保证了无论同一个请求被执行了多少次，而最终只生效一次（这里特指写入操作，译者注）。一个很好的例子就是支付系统。如果一个客户端请求付钱，操作成功之后由于请求超时客户端重新发起了这个请求，这时幂等的系统不会重复扣费。对于没有考虑幂等的系统，会重复扣费。</p>

<p>出于幂等的考量，分布式系统会引入某种形式的分布式锁策略。这是最早被引入分布式系统的概念之一。假设我们打算引入乐观锁（optimistic locking）来解决并发更新的问题。而为了实现乐观锁，又要求系统的强一致性，因为这样才能在操作时使用某种版本控制来检查是否有另外的操作在进行中。</p>

<p>取决于系统层面的约束和操作的类型，有很多实现幂等性的方式。设计如何实现幂等性是一个不错的挑战，Ben Nadel <a href="https://www.bennadel.com/blog/3390-considering-strategies-for-idempotency-without-distributed-locking-with-ben-darfler.htm">写了</a>他用过的不同策略，包括分布式锁和数据库约束。在设计分布式系统时，幂等性是最容易被忽略的部分之一，我的团队就因为没有确保某些关键操作正确的幂等性而付出过惨痛教训。</p>

<p><strong>为什么幂等性对于构建一个支付系统如此重要呢？</strong> 最重要的是：避免重复扣费和重复退款。前面提到了我们的消息系统确保消息至少被投递一次，可以想象所有消息都有可能被投递多次而系统就必须确保幂等性。我们最终选择了使用版本控制和乐观锁来解决这个问题，这个幂等性的系统则使用拥有强一致性的持久化存储作为数据源。</p>

<h2>Sharding 和 Quorum</h2>

<p>分布式系统通常会存储巨量的数据，超过了单个节点的能力范围。所以如何在一组机器上存储一批数据呢？最常用的做法就是 <a href="https://en.wikipedia.org/wiki/Shard_(database_architecture">sharding</a>)。数据基于某种哈希算法被水平的拆分。尽管大部分分布式系统的 sharding 策略都在底层，但 sharding 是一个学起来很有趣的领域，尤其是 <a href="https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6">resharding</a>。Foursquare 曾经在 2010 年由于一个 sharding 的边界问题导致了 17 个小时的宕机，之后有一篇<a href="http://highscalability.com/blog/2010/10/15/troubles-with-sharding-what-can-we-learn-from-the-foursquare.html">很棒的文章</a>分享了问题的根本原因。</p>

<p>许多分布式系统在多个节点上存储数据或进行计算。为了保证操作的一致性，一个基于投票的方案被发明，简言之必须有一定数量的节点都得到相同的结果操作才算成功。这个方案就是 quorum。</p>

<p><strong>为什么 sharding 和 quorum 对于构建一个支付系统如此重要呢？</strong> 这其实是分布式系统非常基础的两个概念。我个人在我们设置 Cassandra 复制策略的时候第一次遇到它们。Cassandra (或是其他分布式系统) 使用 quorum 和本地的 quorum 来确保集群的一致性。一个有趣的现象是，当我们开会的时候，一旦会议室有足够的人就有人会问：“可以开始了吗？我们有 quorum 机制吗？”（译者注，意思是并非所有人都在，大部分在也可以保证会议效果，和 quorum 一样 :D）</p>

<h2>Actor Model</h2>

<p>通常我们使用的一些编程词汇，诸如变量、接口、方法调用等等，都基于单台主机的系统（译者注，我觉得这里想表达的应该是单个进程内部，和后面的做对比）。当讨论分布式系统时，我们需要另外一种方式来表达。一种通用的描述这类系统的模型叫 <a href="https://en.wikipedia.org/wiki/Actor_model">actor model</a>，我们使用这个模型来描述系统间的通信。这个模型非常流行，是因为它和我们实际生活中的心智模型相匹配，比如人在一个组织中如何互相交流。而另外一个流行的模型叫做 <a href="https://en.wikipedia.org/wiki/Communicating_sequential_processes">CSP</a> —— communicating sequential processes。</p>

<p>Actor model 基于 actor 如何相互发送信息和做出反应。每个 actor 被定义了有限的一系列行为——创造其他 actor，发送消息或是决定下一步的动作。只需要一些简单的规则，就可以很好的描述一个复杂的分布式系统，甚至在一个 actor 崩溃之后还能自我修复。我推荐 Brian Storti 的这篇 <a href="https://www.brianstorti.com/the-actor-model/">The actor model in 10 minutes</a> 作为简介。许多编程语言都实现了 actor model 的<a href="https://en.wikipedia.org/wiki/Actor_model#Actor_libraries_and_frameworks">类库或框架</a>，我们在 Uber 的一些项目中就使用了 <a href="https://doc.akka.io/docs/akka/2.4/intro/what-is-akka.html">Akka 工具包</a>。</p>

<p><strong>为什么 actor model 对于构建一个支付系统如此重要呢？</strong> 我们有很多工程师参与构建这个系统，其中很多人都有分布式系统的开发经验。我们决定遵循一种现行标准，而不是自己造轮子。</p>

<h2>Reactive 架构</h2>

<p>构建大型分布式系统的时候，目标通常是有弹性的、可伸缩的、可扩展的。可以是支付系统或是其他类似的高负载系统，可以使用相同的模式来实现这些目标。业内人士已经总结并分享了相关工作的最佳实践——而 Reactive 架构是其中最流行和广泛接受的。</p>

<p>想要快速了解 Reative 架构，我建议读读这篇 <a href="https://www.reactivemanifesto.org/">Reactive 宣言</a> 然后看一下这个 <a href="https://www.lightbend.com/blog/understand-reactive-architecture-design-and-programming-in-less-than-12-minutes">12 分钟的视频</a>。</p>

<p><strong>为什么 Reactive 架构 对于构建一个支付系统如此重要呢？</strong> Akka，也就是之前提到过的我们用来搭建支付系统的类库，深受 Reactive 架构的影响。许多我们的工程师对这套最佳实践也非常熟悉，所以遵循这些原则——响应式的、可伸缩的、有弹性的、消息驱动的——来构建这个系统变得非常自然。能有一种模型可以用来回溯和检查事情是否进展顺利是非常有用的，将来再构建新的系统我还会使用这个模型。</p>

<h2>结束语</h2>

<p>我非常幸运的有机会来重建一个及其关键的大型分布式系统：支撑 Uber 的支付系统。我接触到了许多之前不太熟悉的分布式的相关概念。所以我稍作总结，希望能对其他刚刚接触或者继续学习分布式系统的人有帮助。</p>

<p>这篇文章非常集中在如何设计一个系统的架构。还有很多事情可以讲，比如开发、部署、迁移以及如何可靠的运维这些系统。但这些话题需要其他的文章来描述。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Twelve-Factor App]]></title>
    <link href="https://liangshan.blog/blog/2014/05/22/the-twelve-factor-app/"/>
    <updated>2014-05-22T16:37:03+08:00</updated>
    <id>https://liangshan.blog/blog/2014/05/22/the-twelve-factor-app</id>
    <content type="html"><![CDATA[<p>前些年翻译的 <a href="http://12factor.net/">12-factor</a>。一直放在公司内部的博客上，现在复制一份过来。</p>

<hr />

<p><img class="right <a" src="href="http://0.gravatar.com/avatar/7cdf5b1c46308979e3bf81390b0c8639">http://0.gravatar.com/avatar/7cdf5b1c46308979e3bf81390b0c8639</a>&#8221;></p>

<p>中文翻译：<a href="https://github.com/liangshan/">梁山</a>
英文原文：<a href="http://www.12factor.net/">Adam Wiggins</a></p>

<p><em><a href="https://github.com/liangshan/12factor/issues">翻译问题反馈</a></em></p>

<h4>简介</h4>

<p>如今，软件通常会作为一种服务来交付，它们被称为“互联网应用程序”（web apps），或“软件即服务”（SaaS）。这篇“<strong><em>互联网应用的十二要素</em></strong>”为构建如下的互联网应用程序提供了指导方法：</p>

<ul>
<li>使用<strong>标准化</strong>流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目；</li>
<li>和操作系统之间尽可能的<strong>划清界限</strong>，在各个系统中提供<strong>最大的可移植性</strong>；</li>
<li>适合<strong>部署</strong>在现代的<strong>云计算平台</strong>，从而在服务器和系统管理方面节省资源；</li>
<li>将开发环境和生产环境的<strong>差异降至最低</strong>，并使用<strong>持续交付</strong>实施敏捷开发；</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现<strong>扩展</strong>；</li>
</ul>


<p>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</p>

<h4>背景</h4>

<p>本文的贡献者参与过数以百计的应用程序的开发和部署，并通过 <a href="http://www.heroku.com/">Heroku</a> 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>

<p>本文综合了我们关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 <a href="http://blog.heroku.com/archives/2011/6/28/the_new_heroku_4_erosion_resistance_explicit_contracts/">避免软件污染</a>。</p>

<p>我们的初衷是分享在现代软件开发过程中发现的一些系统性问题，并加深对这些问题的认识。我们提供了讨论这些问题时所需的共享词汇，同时使用相关术语给出一套针对这些问题的广义解决方案。本文格式的灵感来自于 Martin Fowler 的书籍：<a href="http://books.google.com/books/about/Patterns_of_enterprise_application_archi.html?id=FyWZt5DdvFkC"><em>Patterns of Enterprise Application Architecture</em></a>，<a href="http://books.google.com/books/about/Refactoring.html?id=1MsETFPD3I0C"><em>Refactoring</em></a>。</p>

<h4>读者应该是哪些人？</h4>

<p>任何 SaaS 应用的开发人员；部署和管理此类应用的运维工程师。</p>

<!-- more -->


<h2>I. 基准代码</h2>

<p><strong><em>一份基准代码（<em>Codebase</em>），多份部署（<em>deploy</em>）</em></strong></p>

<p>12-Factor App（译者注：应该是说一个使用本文概念来设计的应用，下同）通常会使用版本控制系统加以管理，如 <a href="http://git-scm.com/">Git</a>, <a href="http://mercurial.selenic.com/">Mercurial</a>, <a href="http://subversion.apache.org/">Subversion</a>。一份用来跟踪代码所有修订版本的数据库被称作 <em>代码库</em>（code repository, code repo, repo）。</p>

<p>在类似 SVN 这样的集中式版本控制系统中， <em>基准代码</em> 就是指控制系统中的这一份代码库；而在 Git 那样的分布式版本控制系统中， <em>基准代码</em> 则是指最上游的那份代码库。</p>

<p><img src="https://github.com/anjuke/12factor/raw/zh_CN/public/images/codebase-deploys.png" alt="一份代码库对应多份部署" /></p>

<p>基准代码和应用之间总是保持一一对应的关系：</p>

<ul>
<li>一旦有多个基准代码，就不能称为一个应用，而是一个分布式系统。分布式系统中的每一个组件都是一个应用，每一个应用可以分别使用 12-Factor 进行开发。</li>
<li>多个应用共享一份基准代码是有悖于 12-Factor 原则的。解决方案是将共享的代码拆分为独立的类库，然后使用 <a href="#dependencies">依赖管理</a> 策略去加载它们。</li>
</ul>


<p>尽管每个应用只对应一份基准代码，但可以同时存在多份部署。每份 <em>部署</em> 相当于运行了一个应用的实例。通常会有一个生产环境，一个或多个预发布环境。此外，每个开发人员都会在自己本地环境运行一个应用实例，这些都相当于一份部署。</p>

<p>所有部署的基准代码相同，但每份部署可以使用其不同的版本。比如，开发人员可能有一些提交还没有同步至预发布环境；预发布环境也有一些提交没有同步至生产环境。但它们都共享一份基准代码，我们就认为它们只是相同应用的不同部署而已。</p>

<h2>II. 依赖</h2>

<p><strong><em>显式声明依赖关系(<em>dependency</em>)</em></strong></p>

<p>大多数编程语言都会提供一个打包系统，用来为各个类库提供打包服务，就像 Perl 的 <a href="http://www.cpan.org/">CPAN</a> 或是 Ruby 的 <a href="http://rubygems.org/">Rubygems</a>。通过打包系统安装的类库可以是系统级的（称之为 &ldquo;site packages&#8221;），或仅供某个应用程序使用，部署在相应的目录中（称之为 &#8220;vendoring&rdquo; 或 &ldquo;bunding&#8221;）。</p>

<p><strong>12-Factor 规则下的应用程序不会隐式依赖系统级的类库。</strong> 它一定通过 <em>依赖清单</em> ，确切地声明所有依赖项。此外，在运行过程中通过 <em>依赖隔离</em> 工具来确保程序不会调用系统中存在但清单中未声明的依赖项。这一做法会统一应用到生产和开发环境。</p>

<p>例如，Ruby 的 <a href="http://gembundler.com/">Gem Bundler</a> 使用 <code>Gemfile</code> 作为依赖项声明清单，使用 <code>bundle exec</code> 来进行依赖隔离。Python 中则可分别使用两种工具 &ndash; <a href="http://www.pip-installer.org/en/latest/">Pip</a> 用作依赖声明，<a href="http://www.virtualenv.org/en/latest/">Virtualenv</a> 用作依赖隔离。甚至 C 语言也有类似工具，<a href="http://www.gnu.org/s/autoconf/">Autoconf</a> 用作依赖声明，静态链接库用作依赖隔离。无论用什么工具，依赖声明和依赖隔离必须一起使用，否则无法满足 12-Factor 规范。</p>

<p>显式声明依赖的优点之一是为新进开发者简化了环境配置流程。新进开发者可以检出应用程序的基准代码，安装编程语言环境和它对应的依赖管理工具，只需通过一个 <em>构建命令</em> 来安装所有的依赖项，即可开始工作。例如，Ruby/Bundler 下使用<code>bundle install</code>，而 Clojure/<a href="https://github.com/technomancy/leiningen#readme">Leiningen</a> 则是 <code>lein deps</code>。</p>

<p>12-Factor 应用同样不会隐式依赖某些系统工具，如 ImageMagick 或是<code>curl</code>。即使这些工具存在于几乎所有系统，但终究无法保证所有未来的系统都能支持应用顺利运行，或是能够和应用兼容。如果应用必须使用到某些系统工具，那么这些工具应该被包含在应用之中。</p>

<h2>III. 配置</h2>

<p><strong><em>在环境中存储配置</em></strong></p>

<p>通常，应用的 <em>配置</em> 在不同<a href="#codebase">部署</a> (预发布、生产环境、开发环境等等)间会有很大差异。这其中包括：</p>

<ul>
<li>数据库，Memcached，以及其他 <a href="#backing-services">后端服务</a> 的配置</li>
<li>第三方服务的证书，如 Amazon S3、Twitter 等</li>
<li>每份部署特有的配置，如域名等</li>
</ul>


<p>有些应用在代码中使用常量保存配置，这与 12-factor 所要求的<strong>代码和配置严格分离</strong>显然大相径庭。配置文件在各部署间存在大幅差异，代码却完全一致。</p>

<p>判断一个应用是否正确地将配置排除在代码之外，一个简单的方法是看该应用的基准代码是否可以立刻开源，而不用担心会暴露任何敏感的信息。</p>

<p>需要指出的是，这里定义的&#8221;配置&#8221;并<strong>不</strong>包括应用的内部配置，比如 Rails 的 <code>config/routes.rb</code>，或是使用 <a href="http://www.springsource.org/">Spring</a> 时 <a href="http://static.springsource.org/spring/docs/2.5.x/reference/beans.html">代码模块间的依赖注入关系</a>。这类配置在不同部署间不存在差异，所以应该写入代码。</p>

<p>另外一个解决方法是使用配置文件，但不把它们纳入版本控制系统，就像 Rails 的 <code>config/database.yml</code>。这相对于在代码中使用常量已经是长足进步，但仍然有缺点：总是会不小心将配置文件签入了代码库；配置文件的可能会分散在不同的目录，并有着不同的格式，这让找出一个地方来统一管理所有配置变的不太现实。更糟的是，这些格式通常是语言或框架特定的。</p>

<p><strong>12-Factor 推荐将应用的配置存储于<em>环境变量</em>中</strong> （<em>env vars</em>, <em>env</em>）。环境变量可以非常方便地在不同的部署间做修改，却不动一行代码；与配置文件不同，不小心把它们签入代码库的概率微乎其微；与一些传统的解决配置问题的机制（比如 Java 的属性配置文件）相比，环境变量与语言和系统无关。</p>

<p>配置管理的另一个方面是分组。有时应用会将配置按照特定部署进行分组（或叫做“环境”），例如 Rails 中的 <code>development</code>、<code>test</code> 和 <code>production</code>环境。这种方法无法轻易扩展：更多部署意味着更多新的环境，例如 <code>staging</code> 或 <code>qa</code> 。随着项目的不断深入，开发人员可能还会添加他们自己的环境，比如 <code>joes-staging</code>，这将导致各种配置组合的激增，从而给管理部署增加了很多不确定因素。</p>

<p>12-Factor 应用中，环境变量的粒度要足够小，且相对独立。它们永远也不会组合成一个所谓的“环境”，而是独立存在于每个部署之中。当应用程序不断扩展，需要更多种类的部署时，这种配置管理方式能够做到平滑过渡。</p>

<h2>IV. 后端服务</h2>

<p><strong><em>把后端服务（<em>backing services</em>）当作附加资源</em></strong></p>

<p><em>后端服务</em> 是指程序运行所需要的通过网络调用的各种服务，如数据库（<a href="http://dev.mysql.com/">MySQL</a>，<a href="http://couchdb.apache.org/">CouchDB</a>），消息/队列系统（<a href="http://www.rabbitmq.com/">RabbitMQ</a>，<a href="http://kr.github.com/beanstalkd/">Beanstalkd</a>），SMTP 邮件发送服务（<a href="http://www.postfix.org/">Postfix</a>），以及缓存系统（<a href="http://memcached.org/">Memcached</a>）。</p>

<p>类似数据库的后端服务，通常由部署应用程序的系统管理员一起管理。除了本地服务之外，应用程序有可能使用了第三方发布和管理的服务。示例包括 SMTP（例如 <a href="http://postmarkapp.com/">Postmark</a>），数据收集服务（例如 <a href="http://newrelic.com/">New Relic</a> 或 <a href="http://www.loggly.com/">Loggly</a>），数据存储服务（如 <a href="http://http://aws.amazon.com/s3/">Amazon S3</a>），以及使用 API 访问的服务（例如 <a href="http://dev.twitter.com/">Twitter</a>, <a href="http://code.google.com/apis/maps/index.html">Google Maps</a>, <a href="http://www.last.fm/api">Last.fm</a>）。</p>

<p><strong>12-Factor 应用不会区别对待本地或第三方服务。</strong> 对应用程序而言，两种都是附加资源，通过一个 url 或是其他存储在 <a href="#config">配置</a> 中的服务定位/服务证书来获取数据。12-Factor 应用的任意 <a href="#codebase">部署</a> ，都应该可以在不进行任何代码改动的情况下，将本地 MySQL 数据库换成第三方服务(例如 <a href="http://aws.amazon.com/rds/">Amazon RDS</a>)。类似的，本地 SMTP 服务应该也可以和第三方SMTP服务(例如Postmark)互换。上述 2 个例子中，仅需修改配置中的资源地址。</p>

<p>每个不同的后端服务是一份<em>资源</em>。例如，一个 MySQL 数据库是一个资源，两个 MySQL 数据库(用来数据分区)就被当作是 2 个不同的资源。12-Factor 应用将这些数据库都视作<em>附加资源</em>，并且与这些附加资源保持松耦合。</p>

<p><img src="https://github.com/anjuke/12factor/raw/zh_CN/public/images/attached-resources.png" alt="一种部署附加4个后端服务" /></p>

<p>部署可以按需加载或卸载资源。例如，如果应用的数据库服务由于硬件问题出现异常，管理员可以从最近的备份中恢复一个数据库，卸载当前的数据库，然后加载新的数据库 &ndash; 整个过程都不需要修改代码。</p>

<h2>V. 构建，发布，运行</h2>

<p><strong><em>严格分离构建和运行</em></strong></p>

<p><a href="#codebase">基准代码</a> 转化为一份部署(非开发环境)需要以下三个阶段：</p>

<ul>
<li><em>构建阶段</em>是指将代码仓库转化为可执行包的过程。构建时会使用指定版本的代码，获取和打包 <a href="#dependencies">依赖项</a>，编译成二进制文件和资源文件。</li>
<li><em>发布阶段</em>会将构建的结果和当前部署所需 <a href="#config">配置</a> 相结合，并能够立刻在运行环境中投入使用。</li>
<li><em>运行阶段</em>（或者说“运行时”）是指针对选定的发布版本，在执行环境中启动一系列应用程序 <a href="#processes">进程</a>。</li>
</ul>


<p><img src="https://github.com/anjuke/12factor/raw/zh_CN/public/images/release.png" alt="代码被构建，然后和配置结合成为发布版本" /></p>

<p><strong>12-facfor应用严格区分构建、发布、运行这三个步骤。</strong> 举例来说，直接修改处于运行状态的代码是非常不可取的做法，因为这些修改很难再同步回构建步骤。</p>

<p>部署工具通常都提供了发布管理工具，最引人注目的功能是退回至较旧的发布版本。比如，<a href="https://github.com/capistrano/capistrano/wiki">Capistrano</a> 将所有发布版本都存储在一个叫 <code>releases</code> 的子目录中，当前的在线版本只需映射至对应的目录即可。该工具的 <code>rollback</code> 命令可以很容易地实现回退版本的功能。</p>

<p>每一个发布版本必须对应一个唯一的发布 ID，例如可以使用发布时的时间戳(<code>2011-04-06-20:32:17</code>)，亦或是一个增长的数字(<code>v100</code>) 。发布的版本就像一本只能追加的账本，一旦发布就不可修改，任何的变动都应该产生一个新的发布版本。</p>

<p>新的代码在部署之前，需要开发人员触发构建操作。但是，运行阶段不一定需要人为触发，而是可以自动进行。如服务器重启，或是进程管理器重启了一个崩溃的进程。因此，运行阶段应该保持尽可能少的模块，这样假设半夜发生系统故障而开发人员又捉襟见肘也不会引起太大问题。构建阶段是可以相对复杂一些的，因为错误信息能够立刻展示在开发人员面前，从而得到妥善处理。</p>

<h2>VI. 进程</h2>

<p><strong><em>以一个或多个无状态进程运行应用</em></strong></p>

<p>运行环境中，应用程序通常是以一个和多个<em>进程</em>运行的。</p>

<p>最简单的场景中，代码是一个独立的脚本，运行环境是开发人员自己的笔记本电脑，进程由一条命令行（例如 <code>python my_script.py</code>）。另外一个极端情况是，复杂的应用可能会使用很多 <a href="#concurrency">进程类型</a>，也就是零个或多个进程实例。</p>

<p><strong>12-factor应用的进程必须无状态且 <a href="http://en.wikipedia.org/wiki/Shared_nothing_architecture">无共享</a> 。</strong> 任何需要持久化的数据都要存储在 <a href="#backing-services">后端服务</a> 内，比如数据库。</p>

<p>内存区域或磁盘空间可以作为进程在做某种事务型操作时的缓存，例如下载一个很大的文件，对其操作并将结果写入数据库的过程。12-Factor 应用根本不用考虑这些缓存的内容是不是可以保留给之后的请求来使用，这是因为应用启动了多种类型的进程，将来的请求多半会由其他进程来服务。即使在只有一个进程的情形下，先前保存的数据（内存或文件系统中）也会因为重启（如代码部署、配置更改、或运行环境将进程调度至另一个物理区域执行）而丢失。</p>

<p>源文件打包工具（<a href="http://documentcloud.github.com/jammit/">Jammit</a>, <a href="http://code.google.com/p/django-assetpackager/">django-assetpackager</a>) 使用文件系统来缓存编译过的源文件。12-Factor 应用更倾向于在 <a href="#build-release-run">构建步骤</a> 做此动作——正如 <a href="http://ryanbigg.com/guides/asset_pipeline.html">Rails资源管道</a>，而不是在运行阶段。</p>

<p>一些互联网系统依赖于“<a href="http://en.wikipedia.org/wiki/Load_balancing_%28computing%29#Persistence">粘性 session </a>”，这是指将用户 session 中的数据缓存至某进程的内存中，并将同一用户的后续请求路由到同一个进程。粘性 session 是 12-Factor 极力反对的。Session 中的数据应该保存在诸如 <a href="http://memcached.org/">Memcached</a> 或 <a href="http://redis.io/">Redis</a> 这样的带有过期时间的缓存中。</p>

<h2>VII. 端口绑定</h2>

<p><strong><em>通过端口绑定(<em>Port binding</em>)来提供服务</em></strong></p>

<p>互联网应用有时会运行于服务器的容器之中。例如 PHP 经常作为 <a href="http://httpd.apache.org/">Apache HTTPD</a> 的一个模块来运行，正如 Java 运行于 <a href="http://tomcat.apache.org/">Tomcat</a>。</p>

<p><strong>12-Factor 应用完全自我加载</strong>而不依赖于任何网络服务器就可以创建一个面向网络的服务。互联网应用<strong>通过端口绑定来提供服务</strong>，并监听发送至该端口的请求。</p>

<p>本地环境中，开发人员通过类似 <code>http://localhost:5000/</code> 的地址来访问服务。在线上环境中，请求统一发送至公共域名而后路由至绑定了端口的网络进程。</p>

<p>通常的实现思路是，将网络服务器类库通过 <a href="#dependencies">依赖声明</a> 载入应用。例如，Python 的 <a href="http://www.tornadoweb.org/">Tornado</a>、Ruby 的<a href="http://code.macournoyer.com/thin/">Thin</a>、Java 以及其他基于 JVM 语言的 <a href="http://jetty.codehaus.org/jetty/">Jetty</a>。完全由<em>用户端</em>，确切的说应该是应用的代码，发起请求。和运行环境约定好绑定的端口即可处理这些请求。</p>

<p>HTTP 并不是唯一一个可以由端口绑定提供的服务。其实几乎所有服务器软件都可以通过进程绑定端口来等待请求。例如，使用 <a href="http://xmpp.org/">XMPP</a> 的 <a href="http://www.ejabberd.im/">ejabberd</a>，以及使用 <a href="http://redis.io/topics/protocol">Redis协议</a> 的 <a href="http://redis.io/">Redis</a>。</p>

<p>还要指出的是，端口绑定这种方式也意味着一个应用可以成为另外一个应用的 <a href="#backing-services">后端服务</a>，调用方将服务方提供的相应 URL 当作资源存入 <a href="#config">配置</a> 以备将来调用。</p>

<h2>VIII. 并发</h2>

<p><strong><em>通过进程模型进行扩展</em></strong></p>

<p>任何计算机程序，一旦启动，就会生成一个或多个进程。互联网应用采用多种进程运行方式。例如，PHP 进程作为 Apache 的子进程存在，随请求按需启动。Java 进程则采取了相反的方式，在程序启动之初 JVM 就提供了一个超级进程储备了大量的系统资源（CPU 和内存），并通过多线程实现内部的并发管理。上述2个例子中，进程是开发人员可以操作的最小单位。</p>

<p><img src="https://github.com/anjuke/12factor/raw/zh_CN/public/images/process-types.png" alt="扩展表现为运行中的进程，工作多样性表现为进程类型。" /></p>

<p><strong>在 12-Factor 应用中，进程是一等公民。</strong> 12-Factor 应用的进程主要借鉴于<a href="http://adam.heroku.com/past/2011/5/9/applying_the_unix_process_model_to_web_apps/"> Unix 守护进程模型</a>。开发人员可以运用这个模型去设计应用架构，将不同的工作分配给不同的<em>进程类型</em>。例如，HTTP 请求可以交给 web 进程来处理，而常驻的后台工作则交由 worker 进程负责。</p>

<p>这并不表示应用不能通过单个进程来处理并发，如使用 VM 运行时的线程机制，或是由 <a href="http://rubyeventmachine.com/">EventMachine</a>、<a href="http://twistedmatrix.com/trac/">Twisted</a>、<a href="http://nodejs.org/">Node.js</a> 等工具提供的异步/事件驱动模型。但是，单个 VM 的垂直扩展能力是有限的，所以应用必须能够扩展到多台物理机器上运行。</p>

<p>在需要对系统进行扩展时，进程模型的作用会大放异彩。<a href="#processes">12-Factor 应用的进程所具备的无共享，水平分区的特性</a>意味着增加并发处理能力会是一项简单而稳妥的操作。这些进程的类型以及每个类型中进程的数量就被称作 <em>进程构成</em>。</p>

<p>12-Factor 应用<a href="http://dustin.github.com/2010/02/28/running-processes.html">不需要作为守护进程启动</a>或是写入 PID 文件。相反的，应该借助操作系统的进程管理器(例如 <a href="http://upstart.ubuntu.com/">Upstart</a>，分布式的进程管理云平台，或在开发环境中使用类似 <a href="http://blog.daviddollar.org/2011/05/06/introducing-foreman.html">Foreman</a> 的工具)，来管理 <a href="#logs">输出流</a>，应对进程崩溃，以及处理用户触发的重启和关闭操作。</p>

<h2>IX. 易处理</h2>

<p><strong><em>快速启动和优雅终止可最大化健壮性</em></strong></p>

<p><strong>12-Factor 应用的 <a href="#processes">进程</a> 是<em>可支配</em>的，意思是说它们可以瞬间开启或停止。</strong> 这有利于快速、弹性的伸缩应用，迅速部署变化的 <a href="#codebase">代码</a> 或 <a href="#config">配置</a> ，稳健的部署应用。</p>

<p>进程应当追求<strong>最小启动时间</strong>。理想状态下，进程从敲下命令到真正启动并等待请求的时间应该只需很短的时间。更少的启动时间提供了更敏捷的 <a href="#build-release-run">发布</a> 以及扩展过程，此外还增加了健壮性，因为进程管理器可以在授权情形下容易的将进程搬到新的物理机器上。</p>

<p>进程<strong>一旦接收 <a href="http://en.wikipedia.org/wiki/SIGTERM">终止信号(<code>SIGTERM</code>)</a> 就会优雅的终止</strong>。就网络进程而言，优雅终止是指停止监听服务的端口，即拒绝所有新的请求，并继续执行当前已接收的请求，然后退出。此类型的进程所隐含的要求是HTTP请求大多都很短(不会超过几秒钟)，而在长时间轮询中，客户端在丢失连接后应该马上尝试重连。</p>

<p>对于worker进程来说，优雅终止是指将当前任务退回队列。例如，<a href="http://www.rabbitmq.com/">RabbitMQ</a> 中，worker 可以发送一个 <a href="http://www.rabbitmq.com/amqp-0-9-1-quickref.html#basic.nack"><code>NACK</code></a> 信号。<a href="http://kr.github.com/beanstalkd/">Beanstalkd</a> 中，任务终止并退回队列会在 worker 断开时自动触发。有锁机制的系统诸如 <a href="https://github.com/collectiveidea/delayed_job#readme">Delayed Job</a> 则需要确定释放了系统资源。此类型的进程所隐含的要求是，任务都应该 <a href="http://en.wikipedia.org/wiki/Reentrant_%28subroutine%29">可重复执行</a>，这主要由将结果包装进事务或是使重复操作 <a href="http://en.wikipedia.org/wiki/Idempotence">幂等</a> 来实现。</p>

<p>进程还应当<strong>在面对突然死亡时保持健壮</strong>，例如底层硬件故障。虽然这种情况比起优雅终止来说少之又少，但终究有可能发生。一种推荐的方式是使用一个健壮的后端队列，例如 <a href="http://kr.github.com/beanstalkd/">Beanstalkd</a>，它可以在客户端断开或超时后自动退回任务。无论如何，12-Factor 应用都应该可以设计能够应对意外的、不优雅的终结。<a href="http://lwn.net/Articles/191059/">Crash-only design</a> 将这种概念转化为 <a href="http://couchdb.apache.org/docs/overview.html">合乎逻辑的理论</a>。</p>

<h2>X. 开发环境与线上环境等价</h2>

<p><strong><em>尽可能的保持开发，预发布，线上环境相同</em></strong></p>

<p>从以往经验来看，开发环境（即开发人员的本地<a href="#codebase">部署</a>）和线上环境（外部用户访问的真实部署）之间存在着很多差异。这些差异表现在以下三个方面：</p>

<ul>
<li><strong>时间差异：</strong> 开发人员正在编写的代码可能需要几天，几周，甚至几个月才会上线。</li>
<li><strong>人员差异：</strong> 开发人员编写代码，运维人员部署代码。</li>
<li><strong>工具差异：</strong> 开发人员或许使用Nginx，SQLite，OS X，而线上环境使用Apache，MySQL以及Linux。</li>
</ul>


<p><strong>12-Factor 应用想要做到 <a href="http://www.avc.com/a_vc/2011/02/continuous-deployment.html">持续部署</a> 就必须缩小本地与线上差异。</strong> 再回头看上面所描述的三个差异:</p>

<ul>
<li>缩小时间差异：开发人员可以几小时，甚至几分钟就部署代码。</li>
<li>缩小人员差异：开发人员不只要编写代码，更应该密切参与部署过程以及代码在线上的表现。</li>
<li>缩小工具差异：尽量保证开发环境以及线上环境的一致性。</li>
</ul>


<p>将上述总结变为一个表格如下：</p>

<table>
  <tr>
    <th></th>
    <th>传统应用</th>
    <th>12-factor应用</th>
  </tr>
  <tr>
    <th>每次部署间隔</th>
    <td>数周</td>
    <td>几小时</td>
  </tr>
  <tr>
    <th>开发人员 vs 运维人员</th>
    <td>不同的人</td>
    <td>相同的人</td>
  </tr>
  <tr>
    <th>开发环境 vs 线上环境</th>
    <td>不同</td>
    <td>尽量接近</td>
  </tr>
</table>


<p><a href="#backing-services">后端服务</a> 是保持开发与线上等价的重要部分，例如数据库，队列系统，以及缓存。许多语言都提供了简化获取后端服务的类库，例如不同类型服务的<em>适配器</em>。下列表格提供了一些例子。</p>

<table>
  <tr>
    <th>类型</th>
    <th>语言</th>
    <th>类库</th>
    <th>适配器</th>
  </tr>
  <tr>
    <td>数据库</td>
    <td>Ruby/Rails</td>
    <td>ActiveRecord</td>
    <td>MySQL, PostgreSQL, SQLite</td>
  </tr>
  <tr>
    <td>队列</td>
    <td>Python/Django</td>
    <td>Celery</td>
    <td>RabbitMQ, Beanstalkd, Redis</td>
  </tr>
  <tr>
    <td>缓存</td>
    <td>Ruby/Rails</td>
    <td>ActiveSupport::Cache</td>
    <td>Memory, filesystem, Memcached</td>
  </tr>
</table>


<p>开发人员有时会觉得在本地环境中使用轻量的后端服务具有很强的吸引力，而那些更重量级的健壮的后端服务应该使用在生产环境。例如，本地使用 SQLite 线上使用 PostgreSQL；又如本地缓存在进程内存中而线上存入 Memcached。</p>

<p><strong>12-Factor 应用的开发人员应该反对在不同环境间使用不同的后端服务</strong>，即使适配器已经可以几乎消除使用上的差异。这是因为，不同的后端服务意味着会突然出现的不兼容，从而导致测试、预发布都正常的代码在线上出现问题。这些错误会给持续部署带来阻力。从应用程序的生命周期来看，消除这种阻力需要花费很大的代价。</p>

<p>与此同时，轻量的本地服务也不像以前那样引人注目。借助于 <a href="http://mxcl.github.com/homebrew/">Homebrew</a>，<a href="https://help.ubuntu.com/community/AptGet/Howto">apt-get</a>等现代的打包系统，诸如 Memcached、PostgreSQL、RabbitMQ 等后端服务的安装与运行也并不复杂。此外，使用类似 <a href="http://www.opscode.com/chef/">Chef</a> 和 <a href="http://docs.puppetlabs.com/">Puppet</a> 的声明式配置工具，结合像 <a href="http://vagrantup.com/">Vagrant</a>这样轻量的虚拟环境就可以使得开发人员的本地环境与线上环境无限接近。与同步环境和持续部署所带来的益处相比，安装这些系统显然是值得的。</p>

<p>不同后端服务的适配器仍然是有用的，因为它们可以使移植后端服务变得简单。但应用的所有部署，这其中包括开发、预发布以及线上环境，都应该使用同一个后端服务的相同版本。</p>

<h2>XI. 日志</h2>

<p><strong><em>把日志当作事件流</em></strong></p>

<p><em>日志</em>使得应用程序运行的动作变得透明。在基于服务器的环境中，日志通常被写在硬盘的一个文件里，但这只是一种输出格式。</p>

<p>日志应该是 <a href="http://adam.heroku.com/past/2011/4/1/logs_are_streams_not_files/">事件流</a> 的汇总，将所有运行中进程和后端服务的输出流按照时间顺序收集起来。日志的原始形式通常是文本文件，一行一个事件（程序异常产生的跟踪信息会跨越多行）。日志没有确定开始和结束，但随着应用在运行会持续的增加。</p>

<p><strong>12-Factor 应用本身从不考虑存储自己的输出流。</strong> 不应该试图去写或者管理日志文件。相反，每一个运行的进程都会直接的标准输出（<code>stdout</code>）事件流。开发环境中，开发人员可以通过这些数据流，实时在终端看到应用的活动。</p>

<p>在预发布或线上部署中，每个进程的输出流由运行环境截获，并将其他输出流整理在一起，然后一并发送给一个或多个最终的处理程序，用于查看或是长期存档。这些存档路径对于应用来说不可见也不可配置，而是完全交给程序的运行环境管理。类似 <a href="https://github.com/heroku/logplex">Logplex</a> 和 <a href="https://github.com/fluent/fluentd">Fluent</a> 的开源工具可以达到这个目的。</p>

<p>这些事件流可以输出至文件，或者在终端实时观察。最重要的，输出流可以发送到 <a href="http://www.splunk.com/">Splunk</a> 这样的日志索引及分析系统，或 <a href="http://hive.apache.org/">Hadoop/Hive</a> 这样的通用数据存储系统。这些系统为查看应用的历史活动提供了强大而灵活的功能，包括：</p>

<ul>
<li>找出过去一段时间特殊的事件。</li>
<li>图形化一个大规模的趋势，比如每分钟的请求量。</li>
<li>根据用户定义的条件实时触发警报，比如每分钟的报错超过某个警戒线。</li>
</ul>


<h2>XII. 管理进程</h2>

<p><strong><em>后台管理任务当作一次性进程运行</em></strong></p>

<p><a href="#concurrency">进程构成</a> 是指用来处理应用的常规业务(比如处理web请求)的一组进程。与此不同，开发人员经常希望执行一些管理或维护应用的一次性任务，例如：</p>

<ul>
<li>运行数据移植（Django 中的 <code>manage.py syncdb</code>, Rails 中的 <code>rake db:migrate</code>）。</li>
<li>运行一个控制台（也被称为 <a href="http://en.wikipedia.org/wiki/Read-eval-print_loop">REPL</a> shell），来执行一些代码或是针对线上数据库做一些检查。大多数语言都通过解释器提供了一个 REPL 工具（<code>python</code> 或 <code>erl</code>） ，或是其他命令（Ruby 使用 <code>irb</code>, Rails 使用 <code>rails console</code>）。</li>
<li>运行一些提交到代码仓库的一次性脚本。</li>
</ul>


<p>一次性管理进程应该和正常的 <a href="#processes">常驻进程</a> 使用同样的环境。这些管理进程和任何其他的进程一样使用相同的 <a href="#codebase">代码</a> 和 <a href="#config">配置</a>，基于某个 <a href="#build-release-run">发布版本</a> 运行。后台管理代码应该随其他应用程序代码一起发布，从而避免同步问题。</p>

<p>所有进程类型应该使用同样的 <a href="#dependencies">依赖隔离</a> 技术。例如，如果 Ruby 的 web 进程使用了命令 <code>bundle exec thin start</code>，那么数据库移植应使用 <code>bundle exec rake db:migrate</code>。同样的，如果一个 Python 程序使用了 Virtualenv，则需要在运行 Tornado Web 服务器和任何<code>manage.py</code> 管理进程时引入 <code>bin/python</code> 。</p>

<p>12-Factor 尤其青睐那些提供了 REPL shell 的语言，因为那会让运行一次性脚本变得简单。在本地部署中，开发人员直接在命令行使用 shell 命令调用一次性管理进程。在线上部署中，开发人员依旧可以使用ssh或是运行环境提供的其他机制来运行这样的进程。</p>
]]></content>
  </entry>
  
</feed>
